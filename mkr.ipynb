{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13792799,"sourceType":"datasetVersion","datasetId":8780312},{"sourceId":13935740,"sourceType":"datasetVersion","datasetId":8863900}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport albumentations as A\nimport numpy as np\nfrom glob import glob\nfrom tqdm import tqdm\nimport shutil\n\nINPUT_DIR = \"/kaggle/input/mkr-logos/mkr nns logos.v2i.yolov11/train/images\"\nOUTPUT_DIR = \"/kaggle/working/augmented_dataset\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T09:08:36.454807Z","iopub.execute_input":"2025-12-03T09:08:36.455566Z","iopub.status.idle":"2025-12-03T09:08:44.422437Z","shell.execute_reply.started":"2025-12-03T09:08:36.455527Z","shell.execute_reply":"2025-12-03T09:08:44.421860Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"if os.path.exists(OUTPUT_DIR):\n    shutil.rmtree(OUTPUT_DIR)\nos.makedirs(f\"{OUTPUT_DIR}/images\", exist_ok=True)\nos.makedirs(f\"{OUTPUT_DIR}/labels\", exist_ok=True)\n\ntransform = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=10, p=0.5),\n    A.Perspective(scale=(0.05, 0.1), p=0.3),\n    A.RandomScale(scale_limit=0.1, p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n    A.GaussianBlur(blur_limit=(3, 5), p=0.1),\n    A.ISONoise(p=0.2),\n], bbox_params=A.BboxParams(format='yolo', min_visibility=0.3, label_fields=['class_labels']))\n\nimage_paths = glob(f\"{INPUT_DIR}/**/*.jpg\", recursive=True) + \\\n              glob(f\"{INPUT_DIR}/**/*.png\", recursive=True) + \\\n              glob(f\"{INPUT_DIR}/**/*.jpeg\", recursive=True)\n\ndef convert_to_yolo_bbox(parts):\n    try:\n        coords = list(map(float, parts))\n        \n        xs = coords[0::2]\n        ys = coords[1::2]\n        \n        if not xs or not ys: return None\n        \n        min_x, max_x = min(xs), max(xs)\n        min_y, max_y = min(ys), max(ys)\n        \n        width = max_x - min_x\n        height = max_y - min_y\n        x_center = min_x + width / 2\n        y_center = min_y + height / 2\n        \n        x_center = max(0, min(1, x_center))\n        y_center = max(0, min(1, y_center))\n        width = max(0, min(1, width))\n        height = max(0, min(1, height))\n        \n        return [x_center, y_center, width, height]\n    except:\n        return None\n\nprint(f\"Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ²Ñ…Ñ–Ğ´Ğ½Ğ¸Ñ… Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½ÑŒ: {len(image_paths)}\")\n\nfor img_path in tqdm(image_paths, desc=\"Processing\"):\n    try:\n        label_path = img_path.replace(\"/images/\", \"/labels/\").rsplit('.', 1)[0] + \".txt\"\n\n        if not os.path.exists(label_path):\n            label_path = img_path.rsplit('.', 1)[0] + \".txt\"\n            \n        if not os.path.exists(label_path):\n            continue\n\n        image = cv2.imread(img_path)\n        if image is None: \n            continue\n            \n        bboxes = []\n        class_labels = []\n        \n        with open(label_path, 'r') as f:\n            lines = f.readlines()\n\n        for line in lines:\n            parts = line.strip().split()\n            if len(parts) > 1:\n                cls = int(float(parts[0]))\n                if len(parts) == 5:\n                    bbox = list(map(float, parts[1:]))\n                else:\n                    bbox = convert_to_yolo_bbox(parts[1:])\n                \n                if bbox:\n                    if bbox[2] > 0 and bbox[3] > 0:\n                        bboxes.append(bbox)\n                        class_labels.append(cls)\n        \n        if not bboxes:\n            continue\n\n        base_name = os.path.splitext(os.path.basename(img_path))[0]\n        cv2.imwrite(f\"{OUTPUT_DIR}/images/{base_name}.jpg\", image)\n        with open(f\"{OUTPUT_DIR}/labels/{base_name}.txt\", 'w') as f:\n            for bbox, cls in zip(bboxes, class_labels):\n                f.write(f\"{cls} {' '.join(map(str, bbox))}\\n\")\n\n        multiplier = 8\n        for i in range(multiplier):\n            try:\n                augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n                \n                if len(augmented['bboxes']) == 0: continue\n                \n                new_name = f\"{base_name}_aug_{i}\"\n\n                cv2.imwrite(f\"{OUTPUT_DIR}/images/{new_name}.jpg\", augmented['image'])\n\n                with open(f\"{OUTPUT_DIR}/labels/{new_name}.txt\", 'w') as f:\n                    for bbox, cls in zip(augmented['bboxes'], augmented['class_labels']):\n                        #bbox = clip_bbox(bbox)\n                        f.write(f\"{cls} {' '.join(map(str, bbox))}\\n\")\n                \n            except Exception as e:\n                pass\n\n    except Exception as e:\n        print(f\"Error: {os.path.basename(img_path)}: {e}\")\n\nprint(f\"Ğ’ÑÑŒĞ¾Ğ³Ğ¾ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½ÑŒ Ğ¿Ñ–ÑĞ»Ñ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ñ–Ñ—: {len(os.listdir(f'{OUTPUT_DIR}/images'))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T09:08:44.423764Z","iopub.execute_input":"2025-12-03T09:08:44.424098Z","iopub.status.idle":"2025-12-03T09:09:11.598709Z","shell.execute_reply.started":"2025-12-03T09:08:44.424079Z","shell.execute_reply":"2025-12-03T09:09:11.597895Z"}},"outputs":[{"name":"stdout","text":"Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ²Ñ…Ñ–Ğ´Ğ½Ğ¸Ñ… Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½ÑŒ: 176\n","output_type":"stream"},{"name":"stderr","text":"Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:27<00:00,  6.50it/s]","output_type":"stream"},{"name":"stdout","text":"Ğ’ÑÑŒĞ¾Ğ³Ğ¾ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½ÑŒ Ğ¿Ñ–ÑĞ»Ñ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ñ–Ñ—: 1569\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install hub-sdk\nimport yaml\nfrom ultralytics import YOLO\n\ndata_config = {\n    'train': '/kaggle/working/augmented_dataset/images', \n    'val': '/kaggle/input/mkr-logos/mkr nns logos.v2i.yolov11/valid/images',\n    'nc': 1,            \n    'names': ['logo']   \n}\n\nwith open('/kaggle/working/data.yaml', 'w') as f:\n    yaml.dump(data_config, f)\n    \nmodel = YOLO('yolo11m.pt') \n\nresults = model.train(\n    data='/kaggle/working/data.yaml',\n    epochs=25,\n    imgsz=640,\n    batch=16,\n    name='logo_detector_v11',\n    project='/kaggle/working/runs'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T09:09:11.599667Z","iopub.execute_input":"2025-12-03T09:09:11.599933Z","iopub.status.idle":"2025-12-03T09:33:56.340410Z","shell.execute_reply.started":"2025-12-03T09:09:11.599912Z","shell.execute_reply":"2025-12-03T09:33:56.339640Z"}},"outputs":[{"name":"stdout","text":"Collecting hub-sdk\n  Downloading hub_sdk-0.0.24-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from hub-sdk) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->hub-sdk) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->hub-sdk) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->hub-sdk) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->hub-sdk) (2025.10.5)\nDownloading hub_sdk-0.0.24-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: hub-sdk\nSuccessfully installed hub-sdk-0.0.24\nCreating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'yolo11m.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 38.8MB 206.4MB/s 0.2s0.1s<0.2s\nUltralytics 8.3.234 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=25, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=logo_detector_v11, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/logo_detector_v11, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 15.5MB/s 0.0s\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n 23        [16, 19, 22]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \nYOLO11m summary: 231 layers, 20,053,779 parameters, 20,053,763 gradients\n\nTransferred 643/649 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 65.4MB/s 0.1s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1905.8Â±1094.6 MB/s, size: 98.7 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/augmented_dataset/labels... 1569 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1569/1569 1.4Kit/s 1.1s0.1s\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/augmented_dataset/labels.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 6.6Â±2.1 MB/s, size: 48.2 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/mkr-logos/mkr nns logos.v2i.yolov11/valid/labels... 50 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 150.1it/s 0.3s.0s\nWARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/mkr-logos/mkr nns logos.v2i.yolov11/valid is not writable, cache not saved.\nPlotting labels to /kaggle/working/runs/logo_detector_v11/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/logo_detector_v11\u001b[0m\nStarting training for 25 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/25      7.81G      1.001      1.128       1.37          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 55.2s0.5ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s5.6s\n                   all         50         58     0.0174      0.259    0.00833    0.00291\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/25      8.12G      1.137      1.035      1.445          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.7it/s 57.0s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.8it/s 0.7s1.5s\n                   all         50         58      0.358      0.138      0.113     0.0747\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/25      8.11G      1.129      1.009       1.45          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 55.7s0.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58      0.409      0.548      0.408      0.222\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/25      8.09G      1.069     0.9404      1.407          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.4s1.1ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58      0.718      0.776      0.807      0.541\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/25      8.12G     0.9933     0.8249      1.339          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.4s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.8it/s 0.7s1.5s\n                   all         50         58      0.824      0.621      0.765        0.5\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/25      8.06G     0.9333      0.809      1.293          0        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.2s1.1ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.8it/s 0.7s1.5s\n                   all         50         58      0.883      0.648      0.762       0.53\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/25      8.11G     0.9562     0.7591      1.321          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.3s0.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.5s\n                   all         50         58      0.942      0.879      0.948      0.712\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/25      8.08G     0.8838     0.6838      1.254          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.4s1.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58      0.926      0.867      0.941      0.745\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/25      8.11G     0.8702     0.6521      1.259          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.4s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58      0.937      0.862      0.937      0.756\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/25      8.07G     0.8442     0.6494      1.241          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.3s0.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.5s\n                   all         50         58      0.861      0.914      0.936      0.755\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      11/25       8.1G     0.8415     0.6264      1.229          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.3s0.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.5s\n                   all         50         58      0.982      0.948      0.951      0.757\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      12/25      8.08G      0.796     0.5795      1.198          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.3s1.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58      0.966      0.978      0.984       0.83\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      13/25      8.12G     0.7632       0.55      1.187          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.4s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.8it/s 0.7s1.5s\n                   all         50         58      0.975      0.897      0.937      0.782\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      14/25      8.07G     0.7641     0.5472      1.184          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.3s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58      0.949      0.962       0.97       0.79\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      15/25      8.11G     0.7713     0.5393      1.186          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.3s1.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.5s\n                   all         50         58      0.948      0.966      0.961      0.813\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      16/25      8.07G     0.6705     0.4302      1.151          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.7it/s 56.8s1.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58      0.932      0.942      0.946       0.82\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      17/25      8.11G     0.6676     0.4029      1.151          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.2s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58       0.96      0.914      0.957      0.809\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      18/25      8.06G     0.6215     0.3812      1.116          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.1s1.1ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.5s\n                   all         50         58      0.915      0.948      0.963       0.81\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      19/25      8.11G     0.5827     0.3787      1.095          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.2s0.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.5s\n                   all         50         58      0.982       0.93      0.952      0.841\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      20/25      8.09G     0.5562     0.3422       1.08          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.3s1.1ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58      0.986      0.931      0.968      0.811\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      21/25      8.12G     0.5288     0.3215      1.042          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.4s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58      0.999      0.931      0.951       0.83\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      22/25      8.06G     0.5175     0.3022       1.04          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.2s1.1ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.5s\n                   all         50         58      0.982      0.931      0.946      0.846\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      23/25      8.11G     0.4774     0.2953      1.023          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.4s1.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58          1      0.927      0.956      0.854\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      24/25      8.08G     0.4806     0.2823      1.032          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.1s1.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.6s\n                   all         50         58       0.98      0.931      0.946      0.848\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      25/25      8.11G     0.4471      0.262      1.009          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 99/99 1.8it/s 56.4s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.8it/s 0.7s1.5s\n                   all         50         58      0.995      0.931      0.945      0.851\n\n25 epochs completed in 0.404 hours.\nOptimizer stripped from /kaggle/working/runs/logo_detector_v11/weights/last.pt, 40.5MB\nOptimizer stripped from /kaggle/working/runs/logo_detector_v11/weights/best.pt, 40.5MB\n\nValidating /kaggle/working/runs/logo_detector_v11/weights/best.pt...\nUltralytics 8.3.234 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11m summary (fused): 125 layers, 20,030,803 parameters, 0 gradients\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.5it/s 0.8s1.5s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         50         58          1      0.927      0.956      0.854\nSpeed: 0.2ms preprocess, 12.2ms inference, 0.0ms loss, 0.9ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/logo_detector_v11\u001b[0m\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import cv2\n\nvideo_path = \"/kaggle/input/logotypes/logos/logo.mp4\"\noutput_path = \"/kaggle/working/logo_detected.mp4\"\n\nbest_model_path = \"/kaggle/working/runs/logo_detector_v11/weights/best.pt\"\nmodel = YOLO(best_model_path)\n\ncap = cv2.VideoCapture(video_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nprint(\"ĞĞ±Ñ€Ğ¾Ğ±ĞºĞ° Ğ²Ñ–Ğ´ĞµĞ¾...\")\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n        \n    results = model.predict(frame, conf=0.9, verbose=False)\n    annotated_frame = results[0].plot()\n    out.write(annotated_frame)\n\ncap.release()\nout.release()\nprint(f\"Ğ’Ñ–Ğ´ĞµĞ¾ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾: {output_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T09:33:56.342361Z","iopub.execute_input":"2025-12-03T09:33:56.342800Z","iopub.status.idle":"2025-12-03T09:34:08.548217Z","shell.execute_reply.started":"2025-12-03T09:33:56.342773Z","shell.execute_reply":"2025-12-03T09:34:08.547594Z"}},"outputs":[{"name":"stdout","text":"ĞĞ±Ñ€Ğ¾Ğ±ĞºĞ° Ğ²Ñ–Ğ´ĞµĞ¾...\nĞ’Ñ–Ğ´ĞµĞ¾ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾: /kaggle/working/logo_detected.mp4\n","output_type":"stream"}],"execution_count":5}]}